{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>\n",
    " <b>ETL</b>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Como paso inicial, se llevó a cabo la apertura y exploración de los datos utilizando las funciones y herramientas disponibles en Google Cloud Platform. Este proceso permitió acceder a los datos y realizar un análisis preliminar para comprender la naturaleza y la estructura de la información con la que estábamos trabajando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se recomienda leer el archivo [diccionario de datos](Diccionario_De_Datos.md) para una comprensión de los datos iniciales proporcionados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Por Estados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a realizar una  función que facilita la lectura y procesamiento de archivos JSON dentro de una carpeta y sus subcarpetas, convirtiéndolos en un DataFrame de pandas y guardándolos como archivos CSV para todos los review sobre estados que nos proporcionaron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer_contenido_carpeta(ruta_carpeta):\n",
    "    \"\"\"\n",
    "    Lee el contenido de una carpeta y devuelve una lista de diccionarios con los datos de los archivos JSON.\n",
    "\n",
    "    Args:\n",
    "        ruta_carpeta (str): Ruta de la carpeta a leer.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de diccionarios con los datos de los archivos JSON.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Verificar si la ruta es un directorio\n",
    "        if os.path.isdir(ruta_carpeta):\n",
    "            # Obtener lista de archivos y directorios en la carpeta\n",
    "            contenido = os.listdir(ruta_carpeta)\n",
    "            \n",
    "            # Lista para almacenar datos de todos los archivos JSON en la carpeta\n",
    "            df = []\n",
    "            \n",
    "            # Recorrer la lista de archivos y directorios\n",
    "            for item in contenido:\n",
    "                item_ruta = os.path.join(ruta_carpeta, item)\n",
    "                \n",
    "                # Si es un archivo, leer si es JSON\n",
    "                if os.path.isfile(item_ruta) and item.endswith('.json'):\n",
    "                    print(\"Leyendo el archivo:\", item_ruta)\n",
    "                    \n",
    "                    # Leer y procesar el archivo JSON\n",
    "                    with open(item_ruta, 'r', encoding='utf-8') as f:\n",
    "                        for line in f:\n",
    "                            df.append(json.loads(line))\n",
    "                \n",
    "                # Si es un directorio, llamar recursivamente a la función\n",
    "                elif os.path.isdir(item_ruta):\n",
    "                    print(f\"Entrando en carpeta: {item_ruta}\")\n",
    "                    subcontenido = leer_contenido_carpeta(item_ruta)\n",
    "                    if subcontenido is not None:\n",
    "                        df.extend(subcontenido)\n",
    "            \n",
    "            # Convertir la lista de diccionarios a DataFrame\n",
    "            df_final = pd.DataFrame(df)\n",
    "            \n",
    "            # Especificar la ruta donde se guardarán los archivos CSV\n",
    "            ruta_guardado = '../csv/Google Maps/reviews-estados'\n",
    "            \n",
    "            # Obtener el nombre de la carpeta que contiene los archivos JSON\n",
    "            nombre_carpeta = os.path.basename(ruta_carpeta)\n",
    "            \n",
    "            # Guardar el DataFrame como CSV en la ruta especificada\n",
    "            nombre_archivo_final = os.path.join(ruta_guardado, nombre_carpeta + '.csv')\n",
    "            df_final.to_csv(nombre_archivo_final, index=False)\n",
    "            print(\"Se guardó con éxito en:\", nombre_archivo_final)                    \n",
    "                    \n",
    "        else:\n",
    "            print(f\"La ruta '{ruta_carpeta}' no es un directorio válido.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer el contenido de la carpeta: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leer_contenido_carpeta('../Data/Google Maps/reviews-estados/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esa crea una función que procesa los archivos JSON de la carpeta metadata-sitios, crea un DataFrame con los datos procesados y, finalmente, guarda ese DataFrame como un archivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def leer_contenido_carpeta(ruta_carpeta):\n",
    "    \"\"\" Lee el contenido de una carpeta y devuelve una lista de archivos y directorios.\n",
    "\n",
    "    Args:\n",
    "        ruta_carpeta (str): Ruta de la carpeta a leer.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de archivos y directorios.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Verificar si la ruta es un directorio\n",
    "        if os.path.isdir(ruta_carpeta):\n",
    "            # Obtener lista de archivos y directorios en la carpeta\n",
    "            contenido = os.listdir(ruta_carpeta)\n",
    "            \n",
    "            # Lista para almacenar datos de todos los archivos JSON en la carpeta\n",
    "            df = []\n",
    "            \n",
    "            # Recorrer la lista de archivos y directorios\n",
    "            for item in contenido:\n",
    "                item_ruta = os.path.join(ruta_carpeta, item)\n",
    "                \n",
    "                # Si es un archivo, leer si es JSON\n",
    "                if os.path.isfile(item_ruta) and item.endswith('.json'):\n",
    "                    print(\"Leyendo el archivo:\", item_ruta)\n",
    "                    \n",
    "                    # Leer y procesar el archivo JSON\n",
    "                    with open(item_ruta, 'r', encoding='utf-8') as f:\n",
    "                        for line in f:\n",
    "                            df.append(json.loads(line))\n",
    "            \n",
    "            # Convertir la lista de diccionarios a DataFrame\n",
    "            df_final = pd.DataFrame(df)\n",
    "            \n",
    "            # Especificar la ruta donde se guardarán los archivos CSV\n",
    "            ruta_guardado = '../csv/Google Maps/metadata-sitios'\n",
    "            \n",
    "            # Obtener el nombre de la carpeta que contiene los archivos JSON\n",
    "            nombre_carpeta = os.path.basename(ruta_carpeta)\n",
    "            \n",
    "            # Guardar el DataFrame como CSV en la ruta especificada\n",
    "            nombre_archivo_final = os.path.join(ruta_guardado, nombre_carpeta + '.csv')\n",
    "            df_final.to_csv(nombre_archivo_final, index=False)\n",
    "            print(\"Se guardó con éxito en:\", nombre_archivo_final)                    \n",
    "                    \n",
    "        else:\n",
    "            print(f\"La ruta '{ruta_carpeta}' no es un directorio válido.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer el contenido de la carpeta: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leer_contenido_carpeta('../Data/Google Maps/metadata-sitios/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yelp User Parquet dividido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_archivo_parquet_en_csv(ruta_archivo_parquet, carpeta_destino_csv, num_filas_por_archivo=450000):\n",
    "    \"\"\" Divide un archivo Parquet en partes más pequeñas y las guarda como CSV.\n",
    "    El archivo Parquet se lee y se divide en partes más pequeñas. Cada parte se guarda como un archivo CSV.\n",
    "    El número de filas por archivo se puede establecer como un parámetro opcional.\n",
    "    Por defecto, el número de filas por archivo es de 450000.\n",
    "    El archivo CSV se guarda en la carpeta especificada como parámetro.\n",
    "    Si la carpeta no existe, se crea.\n",
    "    Si el archivo Parquet no existe, se levanta una excepción.\n",
    "    Si el archivo Parquet está vacío, se levanta una excepción.\n",
    "    Si el archivo Parquet tiene menos filas que el número de filas por archivo, se levanta una excepción.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Leer el archivo Parquet\n",
    "    archivo_grande = pd.read_parquet(ruta_archivo_parquet)\n",
    "\n",
    "    # Dividir el archivo en partes más pequeñas\n",
    "    num_archivos = (len(archivo_grande) // num_filas_por_archivo) + 1\n",
    "\n",
    "    for i in range(num_archivos):\n",
    "        inicio = i * num_filas_por_archivo\n",
    "        fin = min((i + 1) * num_filas_por_archivo, len(archivo_grande))  \n",
    "        archivo_pequeno = archivo_grande.iloc[inicio:fin]\n",
    "        \n",
    "        # Guardar el archivo como CSV\n",
    "        nombre_archivo_csv = f'archivo_pequeno_{i}.csv'\n",
    "        ruta_completa_csv = os.path.join(carpeta_destino_csv, nombre_archivo_csv)\n",
    "        archivo_pequeno.to_csv(ruta_completa_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_archivo_grande = '../Data/Yelp/user.parquet'\n",
    "carpeta_archivos_pequenos_csv = '../csv/Yelp/user/'\n",
    "dividir_archivo_parquet_en_csv(ruta_archivo_grande, carpeta_archivos_pequenos_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yelp Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_archivo_json(ruta_archivo_json, ruta_guardado):\n",
    "    \n",
    "    \"\"\" \n",
    "    Procesa un archivo JSON y lo guarda en un archivo CSV.\n",
    "    Args:\n",
    "        ruta_archivo_json (str): Ruta del archivo JSON a procesar.\n",
    "        ruta_guardado (str): Ruta donde se guardará el archivo CSV resultante.\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if os.path.isfile(ruta_archivo_json) and ruta_archivo_json.endswith('.json'):\n",
    "            nombre_archivo = os.path.splitext(os.path.basename(ruta_archivo_json))[0]\n",
    "            \n",
    "            # Verificar si el nombre del archivo es diferente de \"review\"\n",
    "            if nombre_archivo != \"review\":\n",
    "                print(\"Leyendo el archivo:\", ruta_archivo_json)\n",
    "                with open(ruta_archivo_json, 'r', encoding='utf-8') as f:\n",
    "                    data = [json.loads(line) for line in f]\n",
    "\n",
    "                # Convertir la lista de diccionarios a DataFrame\n",
    "                df = pd.DataFrame(data)\n",
    "\n",
    "                # Guardar el DataFrame como CSV en la ruta especificada\n",
    "                nombre_archivo_csv = os.path.join(ruta_guardado, nombre_archivo + '.csv')\n",
    "                df.to_csv(nombre_archivo_csv, index=False)\n",
    "                print(\"Se guardó con éxito en:\", nombre_archivo_csv)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar el archivo JSON: {e}\")\n",
    "\n",
    "def leer_contenido_carpeta(ruta_carpeta, ruta_guardado):\n",
    "    try:\n",
    "        # Verificar si la ruta es un directorio\n",
    "        if os.path.isdir(ruta_carpeta):\n",
    "            # Obtener lista de archivos y directorios en la carpeta\n",
    "            contenido = os.listdir(ruta_carpeta)\n",
    "            \n",
    "            # Recorrer la lista de archivos y directorios\n",
    "            for item in contenido:\n",
    "                item_ruta = os.path.join(ruta_carpeta, item)\n",
    "                \n",
    "                # Si es un archivo, procesar si es JSON\n",
    "                if os.path.isfile(item_ruta):\n",
    "                    procesar_archivo_json(item_ruta, ruta_guardado)\n",
    "                \n",
    "                # Si es un directorio, llamar recursivamente a la función\n",
    "                elif os.path.isdir(item_ruta):\n",
    "                    print(f\"Entrando en carpeta: {item_ruta}\")\n",
    "                    leer_contenido_carpeta(item_ruta, ruta_guardado)\n",
    "        else:\n",
    "            print(f\"La ruta '{ruta_carpeta}' no es un directorio válido.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer el contenido de la carpeta: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_carpeta = '../Data/Yelp/'\n",
    "ruta_guardado = '../csv/Yelp/'  \n",
    "leer_contenido_carpeta(ruta_carpeta, ruta_guardado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yelp review devidido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_archivo_json_en_csv(ruta_json_grande, carpeta_archivos_pequenos, tamano_archivo_pequeno=450000):\n",
    "    \n",
    "    \"\"\" \n",
    "    Dividir un archivo JSON grande en archivos CSV pequeños.\n",
    "\n",
    "    Parámetros:\n",
    "        ruta_json_grande (str): Ruta del archivo JSON grande.\n",
    "        carpeta_archivos_pequenos (str): Ruta de la carpeta donde se guardarán los archivos CSV pequeños.\n",
    "        tamano_archivo_pequeno (int): Tamaño máximo de cada archivo CSV pequeño (en líneas). Por defecto, 450000.\n",
    "\n",
    "    Retorna:\n",
    "        None. Los archivos CSV pequeños se guardan en la carpeta especificada.\n",
    "    \"\"\"\n",
    "    # Función para escribir un fragmento JSON en un archivo CSV\n",
    "    def escribir_fragmento_csv(numero_archivo, fragmento):\n",
    "        nombre_archivo = f'fragmento_{numero_archivo}.csv'\n",
    "        ruta_archivo = os.path.join(carpeta_archivos_pequenos, nombre_archivo)\n",
    "        with open(ruta_archivo, 'w', newline='', encoding='utf-8') as archivo_csv:\n",
    "            escritor_csv = csv.DictWriter(archivo_csv, fieldnames=fragmento[0].keys())\n",
    "            escritor_csv.writeheader()\n",
    "            escritor_csv.writerows(fragmento)\n",
    "\n",
    "    # Leer el archivo JSON grande y dividirlo en fragmentos más pequeños\n",
    "    with open(ruta_json_grande, 'r', encoding='utf-8') as archivo_grande:\n",
    "        fragmento_actual = []\n",
    "        numero_archivo = 1\n",
    "        for linea in archivo_grande:\n",
    "            objeto_json = json.loads(linea)\n",
    "            fragmento_actual.append(objeto_json)\n",
    "            if len(fragmento_actual) == tamano_archivo_pequeno:\n",
    "                escribir_fragmento_csv(numero_archivo, fragmento_actual)\n",
    "                numero_archivo += 1\n",
    "                fragmento_actual = []\n",
    "        # Escribir el último fragmento si es necesario\n",
    "        if fragmento_actual:\n",
    "            escribir_fragmento_csv(numero_archivo, fragmento_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_json_grande = '../Data/Yelp/review.json'\n",
    "carpeta_archivos_pequenos = '../csv/Yelp/review/'\n",
    "dividir_archivo_json_en_csv(ruta_json_grande, carpeta_archivos_pequenos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee el archivo pickle desde la ubicación especificada\n",
    "buis = pd.read_pickle('../Data/Yelp/business.pkl')\n",
    "\n",
    "# Guarda el DataFrame como un archivo CSV en la ubicación deseada\n",
    "ruta_guardado = '../csv/Yelp/business.csv'\n",
    "buis.to_csv(ruta_guardado, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como primer paso, se llevó a cabo la carga de los datos en la plataforma en la nube Google Cloud Platform (GCP) mediante las funciones descritas anteriormente, lo que nos permitió tener acceso a los datos en Google BigQuery. Posteriormente, una vez definidos los objetivos y alcances del proyecto, procedimos a realizar una extracción de datos para trabajar con la información relevante para nuestro análisis.\n",
    "\n",
    "En esta fase, se llevaron a cabo consultas en BigQuery, aprovechando la robustez de esta herramienta para establecer relaciones entre tablas. A través de estas consultas, logramos extraer únicamente la información que será crucial en las etapas posteriores del proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A través de esta consulta en BigQuery, realizamos la fusión de la información de las tablas \"business\" y \"review\". También aplicamos filtros según la zona donde vamos a desarrollar el análisis y por fecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "consulta_merge_businness_review = \"\"\"\n",
    "SELECT\n",
    "  bussines.business_id,\n",
    "  bussines.name,\n",
    "  bussines.categories,\n",
    "  bussines.city,\n",
    "  bussines.latitude,\n",
    "  bussines.longitude,\n",
    "  bussines.stars AS bussines_stars,\n",
    "  bussines.review_count,\n",
    "  bussines.state,\n",
    "  review.text,\n",
    "  review.date,\n",
    "  review.stars AS review_stars,\n",
    "  review.cool,\n",
    "  review.funny,\n",
    "  review.useful,\n",
    "  review.review_id\n",
    "FROM\n",
    "  `theta-byte-412400.YELP_REVIEW.RAW_REVIEW` AS review\n",
    "JOIN\n",
    "  `theta-byte-412400.YELP_BUSINESS.RAW_BUSINNES` AS bussines\n",
    "ON\n",
    "  review.business_id = bussines.business_id\n",
    "WHERE\n",
    "  DATE(review.date) >= '2021-01-01'\n",
    "  AND bussines.categories LIKE '%Hotel%'\n",
    "  AND bussines.state IN ('CA', 'OR', 'WA', 'AZ', 'NV');\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exportamos el resultado de la consulta en formato JSON para trabajar con estos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4413 entries, 0 to 4412\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype              \n",
      "---  ------          --------------  -----              \n",
      " 0   business_id     4413 non-null   object             \n",
      " 1   name            4413 non-null   object             \n",
      " 2   categories      4413 non-null   object             \n",
      " 3   city            4413 non-null   object             \n",
      " 4   latitude        4413 non-null   float64            \n",
      " 5   longitude       4413 non-null   float64            \n",
      " 6   bussines_stars  4413 non-null   float64            \n",
      " 7   review_count    4413 non-null   int64              \n",
      " 8   state           4413 non-null   object             \n",
      " 9   text            4413 non-null   object             \n",
      " 10  date            4413 non-null   datetime64[ns, UTC]\n",
      " 11  review_stars    4413 non-null   int64              \n",
      " 12  cool            4413 non-null   int64              \n",
      " 13  funny           4413 non-null   int64              \n",
      " 14  useful          4413 non-null   int64              \n",
      " 15  review_id       4413 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(3), int64(5), object(7)\n",
      "memory usage: 551.8+ KB\n"
     ]
    }
   ],
   "source": [
    "ruta_archivo_json = '../Data/bq-results-20240130-200859-1706645377030.json'\n",
    "\n",
    "# Cargar el archivo JSON en un DataFrame de Pandas\n",
    "df = pd.read_json(ruta_archivo_json, lines=True)\n",
    "\n",
    "# Obtener información sobre el número de filas y columnas en el DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>bussines_stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>state</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>funny</th>\n",
       "      <th>useful</th>\n",
       "      <th>review_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yi9udL5fcmBjwcBcygv51Q</td>\n",
       "      <td>Canal Place</td>\n",
       "      <td>Shoe Stores, Fashion, Caterers, Shopping, Hote...</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>29.950999</td>\n",
       "      <td>-90.064996</td>\n",
       "      <td>3.5</td>\n",
       "      <td>112</td>\n",
       "      <td>CA</td>\n",
       "      <td>The Canal Place is full of upscale shopping. W...</td>\n",
       "      <td>2021-11-28 18:53:59+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>zOGcU9618uIIpFCurQz85g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DlU5bGy4imZ5JzZYoQkdSg</td>\n",
       "      <td>College Hunks Hauling Junk &amp; Moving - St Louis</td>\n",
       "      <td>Local Services, Packing Supplies, Home Cleanin...</td>\n",
       "      <td>Saint Louis</td>\n",
       "      <td>38.687635</td>\n",
       "      <td>-90.394208</td>\n",
       "      <td>4.0</td>\n",
       "      <td>139</td>\n",
       "      <td>CA</td>\n",
       "      <td>We had a great experience with College Hunks r...</td>\n",
       "      <td>2021-01-18 03:09:14+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13XkWHVhguwZWHIibguVEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9NfPTgy_L9X57ep_Wq13Iw</td>\n",
       "      <td>Condor Express Whale Watching</td>\n",
       "      <td>Whale Watching Tours, Hotels &amp; Travel, Event P...</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>34.408290</td>\n",
       "      <td>-119.691469</td>\n",
       "      <td>4.5</td>\n",
       "      <td>82</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Honestly, deserves more than 5 stars. I had lo...</td>\n",
       "      <td>2021-06-29 03:26:50+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>gHpNqTAH2FpPCBO6p_YtYA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DlU5bGy4imZ5JzZYoQkdSg</td>\n",
       "      <td>College Hunks Hauling Junk &amp; Moving - St Louis</td>\n",
       "      <td>Local Services, Packing Supplies, Home Cleanin...</td>\n",
       "      <td>Saint Louis</td>\n",
       "      <td>38.687635</td>\n",
       "      <td>-90.394208</td>\n",
       "      <td>4.0</td>\n",
       "      <td>139</td>\n",
       "      <td>CA</td>\n",
       "      <td>I contacted them today 10/2 for a move on 10/2...</td>\n",
       "      <td>2021-10-02 20:03:22+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AWktCbWrHNaT9pMBcr5VcQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UcUgyFueY2LyHe3Zhcuhkg</td>\n",
       "      <td>Best Western Suites Near Opryland</td>\n",
       "      <td>Hotels, Event Planning &amp; Services, Hotels &amp; Tr...</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>36.223499</td>\n",
       "      <td>-86.696996</td>\n",
       "      <td>2.5</td>\n",
       "      <td>48</td>\n",
       "      <td>NV</td>\n",
       "      <td>Stayed 10/13/2021 - 10/17/2021.  Rooms 211 &amp; 2...</td>\n",
       "      <td>2021-10-22 16:41:13+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UFoXp5oL5P8iFAVnYuGejA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                                            name  \\\n",
       "0  yi9udL5fcmBjwcBcygv51Q                                     Canal Place   \n",
       "1  DlU5bGy4imZ5JzZYoQkdSg  College Hunks Hauling Junk & Moving - St Louis   \n",
       "2  9NfPTgy_L9X57ep_Wq13Iw                   Condor Express Whale Watching   \n",
       "3  DlU5bGy4imZ5JzZYoQkdSg  College Hunks Hauling Junk & Moving - St Louis   \n",
       "4  UcUgyFueY2LyHe3Zhcuhkg               Best Western Suites Near Opryland   \n",
       "\n",
       "                                          categories           city  \\\n",
       "0  Shoe Stores, Fashion, Caterers, Shopping, Hote...    New Orleans   \n",
       "1  Local Services, Packing Supplies, Home Cleanin...    Saint Louis   \n",
       "2  Whale Watching Tours, Hotels & Travel, Event P...  Santa Barbara   \n",
       "3  Local Services, Packing Supplies, Home Cleanin...    Saint Louis   \n",
       "4  Hotels, Event Planning & Services, Hotels & Tr...      Nashville   \n",
       "\n",
       "    latitude   longitude  bussines_stars  review_count state  \\\n",
       "0  29.950999  -90.064996             3.5           112    CA   \n",
       "1  38.687635  -90.394208             4.0           139    CA   \n",
       "2  34.408290 -119.691469             4.5            82    AZ   \n",
       "3  38.687635  -90.394208             4.0           139    CA   \n",
       "4  36.223499  -86.696996             2.5            48    NV   \n",
       "\n",
       "                                                text  \\\n",
       "0  The Canal Place is full of upscale shopping. W...   \n",
       "1  We had a great experience with College Hunks r...   \n",
       "2  Honestly, deserves more than 5 stars. I had lo...   \n",
       "3  I contacted them today 10/2 for a move on 10/2...   \n",
       "4  Stayed 10/13/2021 - 10/17/2021.  Rooms 211 & 2...   \n",
       "\n",
       "                       date  review_stars  cool  funny  useful  \\\n",
       "0 2021-11-28 18:53:59+00:00             3     3      0       6   \n",
       "1 2021-01-18 03:09:14+00:00             5     0      0       1   \n",
       "2 2021-06-29 03:26:50+00:00             5     0      0       2   \n",
       "3 2021-10-02 20:03:22+00:00             1     0      0       0   \n",
       "4 2021-10-22 16:41:13+00:00             1     0      0       0   \n",
       "\n",
       "                review_id  \n",
       "0  zOGcU9618uIIpFCurQz85g  \n",
       "1  13XkWHVhguwZWHIibguVEA  \n",
       "2  gHpNqTAH2FpPCBO6p_YtYA  \n",
       "3  AWktCbWrHNaT9pMBcr5VcQ  \n",
       "4  UFoXp5oL5P8iFAVnYuGejA  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como próximo paso, llevamos a cabo un análisis de sentimiento sobre las reseñas que los usuarios proporcionaron, con el objetivo de compararlo posteriormente con las calificaciones en estrellas que estos mismos usuarios otorgan al negocio. De esta manera, buscamos determinar cuál de estos criterios es más fidedigno para nuestra evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>bussines_stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>state</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>funny</th>\n",
       "      <th>useful</th>\n",
       "      <th>review_id</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yi9udL5fcmBjwcBcygv51Q</td>\n",
       "      <td>Canal Place</td>\n",
       "      <td>Shoe Stores, Fashion, Caterers, Shopping, Hote...</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>29.950999</td>\n",
       "      <td>-90.064996</td>\n",
       "      <td>3.5</td>\n",
       "      <td>112</td>\n",
       "      <td>CA</td>\n",
       "      <td>The Canal Place is full of upscale shopping. W...</td>\n",
       "      <td>2021-11-28 18:53:59+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>zOGcU9618uIIpFCurQz85g</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DlU5bGy4imZ5JzZYoQkdSg</td>\n",
       "      <td>College Hunks Hauling Junk &amp; Moving - St Louis</td>\n",
       "      <td>Local Services, Packing Supplies, Home Cleanin...</td>\n",
       "      <td>Saint Louis</td>\n",
       "      <td>38.687635</td>\n",
       "      <td>-90.394208</td>\n",
       "      <td>4.0</td>\n",
       "      <td>139</td>\n",
       "      <td>CA</td>\n",
       "      <td>We had a great experience with College Hunks r...</td>\n",
       "      <td>2021-01-18 03:09:14+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13XkWHVhguwZWHIibguVEA</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9NfPTgy_L9X57ep_Wq13Iw</td>\n",
       "      <td>Condor Express Whale Watching</td>\n",
       "      <td>Whale Watching Tours, Hotels &amp; Travel, Event P...</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>34.408290</td>\n",
       "      <td>-119.691469</td>\n",
       "      <td>4.5</td>\n",
       "      <td>82</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Honestly, deserves more than 5 stars. I had lo...</td>\n",
       "      <td>2021-06-29 03:26:50+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>gHpNqTAH2FpPCBO6p_YtYA</td>\n",
       "      <td>Bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DlU5bGy4imZ5JzZYoQkdSg</td>\n",
       "      <td>College Hunks Hauling Junk &amp; Moving - St Louis</td>\n",
       "      <td>Local Services, Packing Supplies, Home Cleanin...</td>\n",
       "      <td>Saint Louis</td>\n",
       "      <td>38.687635</td>\n",
       "      <td>-90.394208</td>\n",
       "      <td>4.0</td>\n",
       "      <td>139</td>\n",
       "      <td>CA</td>\n",
       "      <td>I contacted them today 10/2 for a move on 10/2...</td>\n",
       "      <td>2021-10-02 20:03:22+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AWktCbWrHNaT9pMBcr5VcQ</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UcUgyFueY2LyHe3Zhcuhkg</td>\n",
       "      <td>Best Western Suites Near Opryland</td>\n",
       "      <td>Hotels, Event Planning &amp; Services, Hotels &amp; Tr...</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>36.223499</td>\n",
       "      <td>-86.696996</td>\n",
       "      <td>2.5</td>\n",
       "      <td>48</td>\n",
       "      <td>NV</td>\n",
       "      <td>Stayed 10/13/2021 - 10/17/2021.  Rooms 211 &amp; 2...</td>\n",
       "      <td>2021-10-22 16:41:13+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UFoXp5oL5P8iFAVnYuGejA</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                                            name  \\\n",
       "0  yi9udL5fcmBjwcBcygv51Q                                     Canal Place   \n",
       "1  DlU5bGy4imZ5JzZYoQkdSg  College Hunks Hauling Junk & Moving - St Louis   \n",
       "2  9NfPTgy_L9X57ep_Wq13Iw                   Condor Express Whale Watching   \n",
       "3  DlU5bGy4imZ5JzZYoQkdSg  College Hunks Hauling Junk & Moving - St Louis   \n",
       "4  UcUgyFueY2LyHe3Zhcuhkg               Best Western Suites Near Opryland   \n",
       "\n",
       "                                          categories           city  \\\n",
       "0  Shoe Stores, Fashion, Caterers, Shopping, Hote...    New Orleans   \n",
       "1  Local Services, Packing Supplies, Home Cleanin...    Saint Louis   \n",
       "2  Whale Watching Tours, Hotels & Travel, Event P...  Santa Barbara   \n",
       "3  Local Services, Packing Supplies, Home Cleanin...    Saint Louis   \n",
       "4  Hotels, Event Planning & Services, Hotels & Tr...      Nashville   \n",
       "\n",
       "    latitude   longitude  bussines_stars  review_count state  \\\n",
       "0  29.950999  -90.064996             3.5           112    CA   \n",
       "1  38.687635  -90.394208             4.0           139    CA   \n",
       "2  34.408290 -119.691469             4.5            82    AZ   \n",
       "3  38.687635  -90.394208             4.0           139    CA   \n",
       "4  36.223499  -86.696996             2.5            48    NV   \n",
       "\n",
       "                                                text  \\\n",
       "0  The Canal Place is full of upscale shopping. W...   \n",
       "1  We had a great experience with College Hunks r...   \n",
       "2  Honestly, deserves more than 5 stars. I had lo...   \n",
       "3  I contacted them today 10/2 for a move on 10/2...   \n",
       "4  Stayed 10/13/2021 - 10/17/2021.  Rooms 211 & 2...   \n",
       "\n",
       "                       date  review_stars  cool  funny  useful  \\\n",
       "0 2021-11-28 18:53:59+00:00             3     3      0       6   \n",
       "1 2021-01-18 03:09:14+00:00             5     0      0       1   \n",
       "2 2021-06-29 03:26:50+00:00             5     0      0       2   \n",
       "3 2021-10-02 20:03:22+00:00             1     0      0       0   \n",
       "4 2021-10-22 16:41:13+00:00             1     0      0       0   \n",
       "\n",
       "                review_id sentiment_analysis  \n",
       "0  zOGcU9618uIIpFCurQz85g            Regular  \n",
       "1  13XkWHVhguwZWHIibguVEA            Regular  \n",
       "2  gHpNqTAH2FpPCBO6p_YtYA              Bueno  \n",
       "3  AWktCbWrHNaT9pMBcr5VcQ            Regular  \n",
       "4  UFoXp5oL5P8iFAVnYuGejA            Regular  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Función para asignar categorías personalizadas\n",
    "def categorizar_sentimiento(polaridad):\n",
    "    if polaridad > 0.5:\n",
    "        return 'Excelente'\n",
    "    elif 0.1 <= polaridad <= 0.5:\n",
    "        return 'Bueno'\n",
    "    elif -0.1 <= polaridad < 0.1:\n",
    "        return 'Regular'\n",
    "    elif -0.5 <= polaridad < -0.1:\n",
    "        return 'Malo'\n",
    "    else:\n",
    "        return 'Muy Malo'\n",
    "\n",
    "# Aplica el análisis de sentimiento solo para reseñas presentes\n",
    "mask = df['text'].notnull()\n",
    "df.loc[mask, 'sentiment_analysis'] = df.loc[mask, 'text'].apply(lambda x: categorizar_sentimiento(TextBlob(str(x)).sentiment.polarity))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorizamos la columna \"review_stars\" asignando las etiquetas de 1 como \"Muy Malo\", 2 como \"Malo\", 3 como \"Regular\", y 4 y 5 como \"Bueno\" y \"Excelente\", respectivamente. Posteriormente, comparamos esta clasificación con nuestro análisis de sentimiento, donde aplicamos también una categorización. En este caso, asignamos las siguientes etiquetas: 0 representa un comentario negativo, 1 un comentario neutro y 2 un comentario positivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define las categorías para las estrellas\n",
    "star_mapping = {1: 'Muy Malo', 2: 'Malo', 3: 'Regular', 4: 'Bueno', 5: 'Excelente'}\n",
    "df['stars_category'] = df['review_stars'].map(star_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars_category</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regular</td>\n",
       "      <td>Regular</td>\n",
       "      <td>3</td>\n",
       "      <td>The Canal Place is full of upscale shopping. W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Excelente</td>\n",
       "      <td>Regular</td>\n",
       "      <td>5</td>\n",
       "      <td>We had a great experience with College Hunks r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excelente</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>5</td>\n",
       "      <td>Honestly, deserves more than 5 stars. I had lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muy Malo</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1</td>\n",
       "      <td>I contacted them today 10/2 for a move on 10/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Muy Malo</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1</td>\n",
       "      <td>Stayed 10/13/2021 - 10/17/2021.  Rooms 211 &amp; 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stars_category sentiment_analysis  review_stars  \\\n",
       "0        Regular            Regular             3   \n",
       "1      Excelente            Regular             5   \n",
       "2      Excelente              Bueno             5   \n",
       "3       Muy Malo            Regular             1   \n",
       "4       Muy Malo            Regular             1   \n",
       "\n",
       "                                                text  \n",
       "0  The Canal Place is full of upscale shopping. W...  \n",
       "1  We had a great experience with College Hunks r...  \n",
       "2  Honestly, deserves more than 5 stars. I had lo...  \n",
       "3  I contacted them today 10/2 for a move on 10/2...  \n",
       "4  Stayed 10/13/2021 - 10/17/2021.  Rooms 211 & 2...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecciona las columnas que deseas mostrar\n",
    "selected_columns = ['stars_category', 'sentiment_analysis','review_stars','text']\n",
    "\n",
    "# Muestra las primeras 20 filas de las columnas seleccionadas\n",
    "df[selected_columns].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observan rápidamente algunas discrepancias entre los dos análisis, creamos una tabla de contingencias para evaluarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stars_category      Bueno  Excelente  Malo  Muy Malo  Regular  Total\n",
      "sentiment_analysis                                                  \n",
      "Bueno                 434       1387   135       260      213   2429\n",
      "Excelente              41        298     2         4        9    354\n",
      "Malo                    5          1    55       389        9    459\n",
      "Muy Malo                0          1     1        45        0     47\n",
      "Regular                53         47   195       716      113   1124\n",
      "Total                 533       1734   388      1414      344   4413\n"
     ]
    }
   ],
   "source": [
    "# Crea la tabla de contingencia\n",
    "contingency_table = pd.crosstab(df['sentiment_analysis'], df['stars_category'], margins=True, margins_name='Total')\n",
    "\n",
    "# Renombra la columna 'All' a 'Total'\n",
    "contingency_table.rename(columns={'All': 'Total'}, inplace=True)\n",
    "\n",
    "# Visualiza la tabla de contingencia\n",
    "print(contingency_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que hay un total de 945 coincidencias entre las dos columnas, de un total de 4413 filas. Se decide realizar una ponderación entre estas dos columnas para tomar en cuenta ambos análisis y llegar a un resultado más fidedigno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se realiza un mapeo de las categorías de la columna \"sentiment_analysis\" a números del 1 al 5, asignándoles un valor numérico acorde a su grado de positividad. Luego, se asignan pesos a las métricas, especificando que la métrica de las estrellas de la revisión tiene un peso del 70%, mientras que el análisis de sentimiento tiene un peso del 30%. Finalmente, se calcula una nueva métrica combinada, donde se promedian ponderadamente los valores de las métricas de las estrellas y el análisis de sentimiento, obteniendo así una medida combinada que refleja tanto la evaluación de los usuarios como el análisis de sentimiento, considerando sus respectivos pesos. Este enfoque permite integrar ambas fuentes de información de manera equilibrada en una sola métrica para evaluar la satisfacción general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeo de categorías a números del 1 al 5\n",
    "sentiment_mapping_numerico = {'Excelente': 5, 'Bueno': 4, 'Regular': 3, 'Malo': 2, 'Muy Malo': 1}\n",
    "\n",
    "# Aplicar el mapeo a la columna sentiment_analysis\n",
    "df['sentiment_analysis_numerico'] = df['sentiment_analysis'].map(sentiment_mapping_numerico)\n",
    "\n",
    "# Asignar pesos a las métricas\n",
    "peso_review_stars = 0.7\n",
    "peso_analisis_sentimiento = 0.3\n",
    "\n",
    "# Calcular métrica combinada\n",
    "df['metrica_combinada'] = (peso_review_stars * df['review_stars'] +\n",
    "                           peso_analisis_sentimiento * df['sentiment_analysis_numerico']) / (peso_review_stars + peso_analisis_sentimiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars_category</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>metrica_combinada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regular</td>\n",
       "      <td>Regular</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Excelente</td>\n",
       "      <td>Regular</td>\n",
       "      <td>5</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excelente</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>5</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muy Malo</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Muy Malo</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stars_category sentiment_analysis  review_stars  metrica_combinada\n",
       "0        Regular            Regular             3                3.0\n",
       "1      Excelente            Regular             5                4.4\n",
       "2      Excelente              Bueno             5                4.7\n",
       "3       Muy Malo            Regular             1                1.6\n",
       "4       Muy Malo            Regular             1                1.6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns = ['stars_category', 'sentiment_analysis','review_stars','metrica_combinada']\n",
    "\n",
    "df[selected_columns].head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
